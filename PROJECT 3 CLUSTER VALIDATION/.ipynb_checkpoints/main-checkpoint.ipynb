{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv file and save data into separate lists\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from scipy.fftpack import fft, ifft\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from datetime import timedelta\n",
    "from scipy.fftpack import fft, ifft,rfft\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from joblib import dump, load\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import iqr\n",
    "from scipy import signal\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project3_insulin_csv_data_dataframe  =  pd.read_csv('InsulinData.csv' ,  low_memory  =  False ,  usecols  =  ['Date' , 'Time' , 'BWZ Carb Input (grams)'])\n",
    "project3_cgm_csv_data_dataframe  =  pd.read_csv('CGMData.csv' , low_memory  =  False , usecols  =  ['Date' , 'Time' , 'Sensor Glucose (mg/dL)'])\n",
    "project3_insulin_csv_data_dataframe['date_time_stamp']  =  pd.to_datetime(project3_insulin_csv_data_dataframe['Date']  +  ' '  +  project3_insulin_csv_data_dataframe['Time'])\n",
    "project3_cgm_csv_data_dataframe['date_time_stamp']  =  pd.to_datetime(project3_cgm_csv_data_dataframe['Date']  +  ' '  +  project3_cgm_csv_data_dataframe['Time'])\n",
    "\n",
    "\n",
    "def fucntion_for_meal_data_extraction(project3_insulin_csv_data_dataframe ,  project3_cgm_csv_data_dataframe ,  id_of_the_date):\n",
    "    copy_of_the_project3_insulin_csv_data_dataframe  =  project3_insulin_csv_data_dataframe.copy()\n",
    "    copy_of_the_project3_insulin_csv_data_dataframe  =  copy_of_the_project3_insulin_csv_data_dataframe.set_index('date_time_stamp')\n",
    "    \n",
    "    # sort by date_time_stamp ,  \n",
    "    sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df = copy_of_the_project3_insulin_csv_data_dataframe.sort_values(by = 'date_time_stamp' , ascending = True).dropna()\n",
    "    sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df['BWZ Carb Input (grams)'].replace(0.0 , np.nan , inplace = True)\n",
    "    sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df = sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df.dropna().reset_index()\n",
    "    sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df = sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df.reset_index().drop(columns = 'index')\n",
    "    \n",
    "    list_of_valid_time_stamps = []\n",
    "    value = 0\n",
    "    for idx , i in enumerate(sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df['date_time_stamp']):\n",
    "        try:\n",
    "            value = (sort_insulin_data_by_time_stamp_and_find_timestamp_with_2_5_hours_df['date_time_stamp'][idx + 1] - i).seconds / 60.0\n",
    "            if value >=  120:\n",
    "                list_of_valid_time_stamps.append(i)\n",
    "        except KeyError:\n",
    "            break\n",
    "        # if idx  =  =  2:\n",
    "        #     break\n",
    "    \n",
    "    \n",
    "    \n",
    "    value_list_1  =  []\n",
    "    value_list_2  =  []\n",
    "    \n",
    "    if id_of_the_date == 1:\n",
    "        \n",
    "        for idx , i in enumerate(list_of_valid_time_stamps):\n",
    "            start = pd.to_datetime(i  -  timedelta(minutes = 30))\n",
    "            end = pd.to_datetime(i  +  timedelta(minutes = 120))\n",
    "            time  =  pd.to_datetime(i)\n",
    "            get_date = i.date().strftime('%#m/%#d/%Y')\n",
    "            x = (project3_insulin_csv_data_dataframe.loc[project3_insulin_csv_data_dataframe['Time'] == time.strftime('%H:%M:%S')]['BWZ Carb Input (grams)'].dropna().values.tolist())\n",
    "            if(len(x) == 0):\n",
    "                continue\n",
    "            value_list_2.append(x)\n",
    "            value_list_1.append(project3_cgm_csv_data_dataframe.loc[project3_cgm_csv_data_dataframe['Date'] == get_date].set_index('date_time_stamp').between_time(start_time = start.strftime('%H:%M:%S') , end_time = end.strftime('%H:%M:%S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    else:\n",
    "        for idx , i in enumerate(list_of_valid_time_stamps):\n",
    "            start = pd.to_datetime(i  -  timedelta(minutes = 30))\n",
    "            end = pd.to_datetime(i  +  timedelta(minutes = 120))\n",
    "            get_date = i.date().strftime('%Y - %m - %d')\n",
    "            x = (project3_insulin_csv_data_dataframe.loc[project3_insulin_csv_data_dataframe['Time'] == time.strftime('%H:%M:%S')]['BWZ Carb Input (grams)'].dropna().values.tolist())\n",
    "            print(x)\n",
    "            if(len(x) == 0):\n",
    "                continue\n",
    "            value_list_2.append(x)\n",
    "            value_list_1.append(project3_cgm_csv_data_dataframe.loc[project3_cgm_csv_data_dataframe['Date'] == get_date].set_index('date_time_stamp').between_time(start_time = start.strftime('%H:%M:%S') , end_time = end.strftime('%H:%M:%S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    \n",
    "    return pd.DataFrame(value_list_1)  ,  pd.DataFrame(value_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_info_about_meal_data , list_info_about_amount_of_meal_data = fucntion_for_meal_data_extraction(project3_insulin_csv_data_dataframe , project3_cgm_csv_data_dataframe , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_info_about_amount_of_meal_data = list_info_about_amount_of_meal_data.drop([1] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_info_about_meal_data = list_info_about_meal_data.iloc[: , 0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_info_about_meal_data  =  list_info_about_meal_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_info_about_amount_of_meal_data  =  list_info_about_amount_of_meal_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_clean_data_and_sample_data(list_info_about_meal_data_to_be_cleaned_and_sampled , list_info_about_amount_of_meal_data_to_be_cleaned_and_sampled):\n",
    "    idx  =  []\n",
    "    meal_data_info_size  =  len(list_info_about_meal_data_to_be_cleaned_and_sampled)\n",
    "    for i in range (meal_data_info_size):\n",
    "        list_info_about_meal_data_to_be_cleaned_and_sampled[i]  =  list_info_about_meal_data_to_be_cleaned_and_sampled[i][:30]\n",
    "        list_info_about_meal_data_to_be_cleaned_and_sampled[i]  =  list_info_about_meal_data_to_be_cleaned_and_sampled[i][:: - 1]\n",
    "        if (len(list_info_about_meal_data_to_be_cleaned_and_sampled[i])!=  30):\n",
    "            idx.append(i)\n",
    "        elif 'nan' in list_info_about_meal_data_to_be_cleaned_and_sampled[i]:\n",
    "            idx.append(i)      \n",
    "    for j in range (len(idx) , 0 ,  - 1):\n",
    "        del list_info_about_meal_data_to_be_cleaned_and_sampled[idx[j - 1]]\n",
    "        del list_info_about_amount_of_meal_data_to_be_cleaned_and_sampled[idx[j - 1]]\n",
    "    return list_info_about_meal_data_to_be_cleaned_and_sampled ,  list_info_about_amount_of_meal_data_to_be_cleaned_and_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_velocity(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    l = []\n",
    "    for i in range(len(cleaned_and_sampled_list_info_about_meal_data) - 1):\n",
    "        l.append(cleaned_and_sampled_list_info_about_meal_data[i + 1] - cleaned_and_sampled_list_info_about_meal_data[i])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acceleration(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    l = []\n",
    "    for i in range(len(cleaned_and_sampled_list_info_about_meal_data) - 1):\n",
    "        l.append(cleaned_and_sampled_list_info_about_meal_data[i + 1] - cleaned_and_sampled_list_info_about_meal_data[i])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_maximum_velocity(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    return max(cleaned_and_sampled_list_info_about_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_minimum_velocity(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    return min(cleaned_and_sampled_list_info_about_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_velocity(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    return sum(cleaned_and_sampled_list_info_about_meal_data)/len(cleaned_and_sampled_list_info_about_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_maximum_acceleration(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    return max(cleaned_and_sampled_list_info_about_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_minimum_acceleration(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    return min(cleaned_and_sampled_list_info_about_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_acceleration(cleaned_and_sampled_list_info_about_meal_data):\n",
    "    return sum(cleaned_and_sampled_list_info_about_meal_data)/len(cleaned_and_sampled_list_info_about_meal_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_of_the_list_info_about_meal_data , copy_of_the_list_info_about_amount_of_meal_data  =  list_info_about_meal_data  ,  list_info_about_amount_of_meal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(copy_of_the_list_info_about_meal_data)):\n",
    "    for j in range(len(copy_of_the_list_info_about_meal_data[0])):\n",
    "        copy_of_the_list_info_about_meal_data[i][j]  =  str(copy_of_the_list_info_about_meal_data[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_of_the_list_info_about_meal_data ,  copy_of_the_list_info_about_amount_of_meal_data  =  function_to_clean_data_and_sample_data(copy_of_the_list_info_about_meal_data ,  copy_of_the_list_info_about_amount_of_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from the processed meal data:  299\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows from the processed meal data: \" , len(copy_of_the_list_info_about_meal_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from the processed meal amount data:  299\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows from the processed meal amount data: \" , len(copy_of_the_list_info_about_amount_of_meal_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_discretize_the_meal_amount_in_bins_of_size_20(copy_of_the_list_info_about_amount_of_meal_data):\n",
    "    meal_amount_in_bins_of_size_20  =  []\n",
    "    for i in range (len(copy_of_the_list_info_about_amount_of_meal_data)):\n",
    "        if (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])>= 0) and (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])<= 20):\n",
    "            meal_amount_in_bins_of_size_20.append(1)\n",
    "        elif (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])>20) and (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])<= 40):\n",
    "            meal_amount_in_bins_of_size_20.append(2)\n",
    "        elif (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])>40) and (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])<= 60):\n",
    "            meal_amount_in_bins_of_size_20.append(3)\n",
    "        elif (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])>60) and (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])<= 80):\n",
    "            meal_amount_in_bins_of_size_20.append(4)\n",
    "        elif (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])>80) and (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])<= 100):\n",
    "            meal_amount_in_bins_of_size_20.append(5)\n",
    "        elif (int(copy_of_the_list_info_about_amount_of_meal_data[i][0])>100):\n",
    "            meal_amount_in_bins_of_size_20.append(6)\n",
    "    return meal_amount_in_bins_of_size_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_containing_the_final_feature_matrix_for_the_meal_data  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(copy_of_the_list_info_about_meal_data)):\n",
    "    \n",
    "    list_of_the_meal_data_as_an_floating_type_array  =  list(np.asarray(copy_of_the_list_info_about_meal_data[i] ,  dtype = np.float32))\n",
    "    \n",
    "    list_containing_velocities_for_each_sample_of_the_meal_data  =  calculate_velocity(list_of_the_meal_data_as_an_floating_type_array)\n",
    "    \n",
    "    calculated_maximum_velcoty_for_the_total_meal_data  =  calculate_maximum_velocity(list_containing_velocities_for_each_sample_of_the_meal_data)\n",
    "    \n",
    "    calculated_minimum_velcoty_for_the_total_meal_data  =  calculate_minimum_velocity(list_containing_velocities_for_each_sample_of_the_meal_data)\n",
    "    \n",
    "    calculated_average_velcoty_for_the_total_meal_data  =  calculate_average_velocity(list_containing_velocities_for_each_sample_of_the_meal_data)\n",
    "\n",
    "    list_containing_accuracies_for_each_sample_of_the_meal_data  =  calculate_acceleration(list_containing_velocities_for_each_sample_of_the_meal_data)\n",
    "    \n",
    "    calculated_maximum_acceleration_for_the_total_meal_data  =  calculate_maximum_acceleration(list_containing_accuracies_for_each_sample_of_the_meal_data)\n",
    "    \n",
    "    calculated_minimum_acceleration_for_the_total_meal_data  =  calculate_minimum_acceleration(list_containing_accuracies_for_each_sample_of_the_meal_data)\n",
    "    \n",
    "    calculated_average_acceleration_for_the_total_meal_data  =  calculate_average_acceleration(list_containing_accuracies_for_each_sample_of_the_meal_data)\n",
    "    \n",
    "    calculated_entropy_for_the_total_meal_data  =  entropy(list_of_the_meal_data_as_an_floating_type_array , base = 2)\n",
    "    \n",
    "    calculated_irq_for_the_total_meal_data  =  iqr(list_of_the_meal_data_as_an_floating_type_array)\n",
    "    \n",
    "    f , power_spectral_density  =  signal.periodogram(list_of_the_meal_data_as_an_floating_type_array)\n",
    "    \n",
    "    power_spectral_density_1  =  sum(power_spectral_density[0:5])/5\n",
    "    \n",
    "    power_spectral_density_2  =  sum(power_spectral_density[5:10])/5\n",
    "    \n",
    "    power_spectral_density_3  =  sum(power_spectral_density[10:16])/6\n",
    "    \n",
    "    fast_fourier_transform_list =  list(np.fft.fft(list_of_the_meal_data_as_an_floating_type_array))\n",
    "    \n",
    "    fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns  =  []\n",
    "    \n",
    "    while len(fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns)<6:\n",
    "        temp  =  max(fast_fourier_transform_list)\n",
    "        mag  =  math.sqrt(np.real(temp)**2 + np.imag(temp)**2)\n",
    "        fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns.append(mag)\n",
    "        del fast_fourier_transform_list[fast_fourier_transform_list.index(temp)]\n",
    "    \n",
    "    f1  =  [calculated_maximum_velcoty_for_the_total_meal_data , calculated_minimum_velcoty_for_the_total_meal_data , calculated_average_velcoty_for_the_total_meal_data , calculated_maximum_acceleration_for_the_total_meal_data , calculated_minimum_acceleration_for_the_total_meal_data , calculated_average_acceleration_for_the_total_meal_data , calculated_entropy_for_the_total_meal_data , calculated_irq_for_the_total_meal_data , fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns[0] , fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns[1] , fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns[2] , fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns[3] , fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns[4] , fast_fourier_transform_list_containing_the_top_6_max_values_resulted_in_the_6_columns[5] , power_spectral_density_1 , power_spectral_density_2 , power_spectral_density_3]\n",
    "    \n",
    "    f1  =  np.asarray(f1 ,  dtype = object)\n",
    "    \n",
    "    if i  ==  0:\n",
    "        list_containing_the_final_feature_matrix_for_the_meal_data  =  f1\n",
    "    else:\n",
    "        list_containing_the_final_feature_matrix_for_the_meal_data  =  np.vstack((list_containing_the_final_feature_matrix_for_the_meal_data , f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_containing_the_final_feature_matrix_for_the_meal_data[0])):\n",
    "    list_containing_the_final_feature_matrix_for_the_meal_data  =  normalize(list_containing_the_final_feature_matrix_for_the_meal_data ,  axis = 0 ,  norm = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6   \\\n",
      "0    0.058296 -0.110169 -0.082540  0.056769 -0.050691  0.162791  0.998796   \n",
      "1    0.089686 -0.194915  0.130159  0.087336 -0.055300  0.093023  0.984455   \n",
      "2    0.067265 -0.067797  0.507937  0.039301 -0.064516  0.046512  0.970723   \n",
      "3    0.017937 -0.101695 -0.374603  0.043668 -0.055300 -0.069767  0.992977   \n",
      "4    0.143498 -0.127119  0.209524  0.052402 -0.064516 -0.813953  0.995951   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "294  0.139013 -0.110169  0.295238  0.104803 -0.156682  0.209302  0.994548   \n",
      "295  0.116592 -0.186441  0.142857  0.061135 -0.087558 -0.139535  0.986990   \n",
      "296  0.147982 -0.101695  0.460317  0.117904 -0.142857  0.093023  0.985629   \n",
      "297  0.089686 -0.110169 -0.003175  0.061135 -0.152074 -0.395349  0.999509   \n",
      "298  0.121076 -0.144068  0.225397  0.135371 -0.069124 -0.418605  0.994482   \n",
      "\n",
      "           7         8         9         10        11        12        13  \\\n",
      "0    0.194731  0.760174  0.272856  0.272856  0.090318  0.090318  0.174666   \n",
      "1    0.136312  0.242103  0.064496  0.064496  0.042478  0.042478  0.024200   \n",
      "2    0.386025  0.339142  0.266500  0.266500  0.131396  0.131396  0.097941   \n",
      "3    0.292096  0.521834  0.173474  0.173474  0.113701  0.113701  0.132783   \n",
      "4    0.210767  0.626201  0.021900  0.021900  0.038718  0.038718  0.051205   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "294  0.331042  0.554609  0.391936  0.391936  0.009266  0.009266  0.057619   \n",
      "295  0.171821  0.344589  0.042280  0.042280  0.026649  0.026649  0.014765   \n",
      "296  0.223368  0.432320  0.124293  0.124293  0.161340  0.161340  0.077624   \n",
      "297  0.090493  0.602139  0.119218  0.119218  0.111454  0.111454  0.034252   \n",
      "298  0.215349  0.459649  0.149035  0.149035  0.003170  0.003170  0.008004   \n",
      "\n",
      "           14        15        16  \n",
      "0    0.049235  0.011952  0.014415  \n",
      "1    0.059698  0.016058  0.023097  \n",
      "2    0.189449  0.238397  0.256654  \n",
      "3    0.109586  0.126287  0.133424  \n",
      "4    0.093825  0.059945  0.077500  \n",
      "..        ...       ...       ...  \n",
      "294  0.107852  0.087882  0.098576  \n",
      "295  0.096546  0.011391  0.022846  \n",
      "296  0.142499  0.201220  0.253134  \n",
      "297  0.013254  0.010435  0.009629  \n",
      "298  0.072653  0.037084  0.053150  \n",
      "\n",
      "[299 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(pd.DataFrame(list_containing_the_final_feature_matrix_for_the_meal_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list_containing_the_final_feature_matrix_for_the_meal_data.pkl' , 'wb') as f:\n",
    "    pickle.dump(list_containing_the_final_feature_matrix_for_the_meal_data ,  f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test.csv' ,  pd.DataFrame(list_containing_the_final_feature_matrix_for_the_meal_data[:60]) ,  fmt = \"%f\" ,  delimiter = \" , \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_amount_in_bins_of_size_20  =  function_to_discretize_the_meal_amount_in_bins_of_size_20(copy_of_the_list_info_about_amount_of_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the list meal_amount_in_bins_of_size_20 containing the bin values for the rows of the meal data\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing the list meal_amount_in_bins_of_size_20 containing the bin values for the rows of the meal data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 4, 3, 3, 6, 2, 1, 5, 1, 2, 6, 5, 3, 2, 3, 2, 3, 2, 2, 5, 3, 5, 1, 1, 2, 4, 1, 3, 2, 3, 3, 4, 1, 2, 3, 2, 1, 2, 4, 2, 1, 2, 3, 5, 2, 2, 1, 3, 3, 5, 3, 6, 3, 2, 5, 3, 1, 2, 4, 6, 2, 2, 2, 2, 5, 4, 2, 2, 2, 3, 1, 4, 3, 2, 4, 2, 3, 1, 5, 1, 3, 5, 3, 3, 3, 5, 3, 1, 3, 3, 3, 3, 2, 2, 5, 3, 2, 5, 3, 3, 1, 2, 2, 2, 3, 1, 3, 2, 1, 2, 2, 3, 4, 3, 1, 5, 3, 2, 4, 3, 4, 4, 3, 4, 4, 2, 1, 2, 5, 1, 1, 2, 3, 3, 2, 1, 2, 2, 3, 1, 1, 3, 2, 4, 1, 3, 2, 1, 1, 3, 1, 1, 3, 3, 2, 5, 1, 3, 1, 1, 1, 2, 1, 3, 2, 1, 4, 1, 2, 2, 4, 2, 4, 2, 4, 1, 1, 4, 2, 1, 1, 5, 2, 4, 3, 4, 2, 3, 1, 2, 1, 2, 2, 3, 3, 1, 4, 2, 2, 3, 2, 3, 2, 1, 4, 5, 2, 2, 1, 5, 1, 3, 4, 1, 3, 3, 4, 2, 1, 1, 1, 3, 2, 5, 1, 1, 1, 1, 2, 1, 2, 2, 4, 1, 2, 2, 2, 5, 1, 1, 2, 1, 3, 3, 2, 2, 1, 3, 2, 1, 1, 4, 3, 1, 3, 2, 3, 2, 1, 4, 2, 2, 3, 1, 5, 2, 3, 3, 2, 1, 1, 1, 2, 4, 1, 1, 2, 2, 3, 2, 5, 3, 2, 3, 1, 3, 3, 4, 2, 1, 2, 1, 5, 2, 1, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "print(meal_amount_in_bins_of_size_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points in Bin 1 =  74\n"
     ]
    }
   ],
   "source": [
    "print(\"number of points in Bin 1 = \" , meal_amount_in_bins_of_size_20.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points in Bin 2 =  90\n"
     ]
    }
   ],
   "source": [
    "print(\"number of points in Bin 2 = \" , meal_amount_in_bins_of_size_20.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points in Bin 3 =  74\n"
     ]
    }
   ],
   "source": [
    "print(\"number of points in Bin 3 = \" , meal_amount_in_bins_of_size_20.count(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points in Bin 4 =  33\n"
     ]
    }
   ],
   "source": [
    "print(\"number of points in Bin 4 = \" , meal_amount_in_bins_of_size_20.count(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points in Bin 5 =  24\n"
     ]
    }
   ],
   "source": [
    "print(\"number of points in Bin 5 = \" , meal_amount_in_bins_of_size_20.count(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points in Bin 6 =  4\n"
     ]
    }
   ],
   "source": [
    "print(\"number of points in Bin 6 = \" , meal_amount_in_bins_of_size_20.count(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_amount_in_bins_of_size_20  =  np.asarray(meal_amount_in_bins_of_size_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BinsMG(result_labels ,  true_label ,  clusterNum):\n",
    "    binResultMG  =  []\n",
    "    generated_bins_by_the_kmeans_model  =  []\n",
    "    for i in range(clusterNum):\n",
    "        binResultMG.append([])\n",
    "        generated_bins_by_the_kmeans_model.append([])\n",
    "    for i in range(len(result_labels)):\n",
    "        binResultMG[result_labels[i] - 1].append(i)\n",
    "    # print(binResultMG)\n",
    "    for i in range(clusterNum):\n",
    "        for j in binResultMG[i]:\n",
    "            generated_bins_by_the_kmeans_model[i].append(true_label[j])\n",
    "    return generated_bins_by_the_kmeans_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SSEValueMG_for_kmeans_calculation(bin_value_and_bins_weighted_value):\n",
    "    sse_value_mg_for_kmeans  =  0\n",
    "    if len(bin_value_and_bins_weighted_value) !=  0:\n",
    "        avg  =  sum(bin_value_and_bins_weighted_value) / len(bin_value_and_bins_weighted_value)\n",
    "        for i in bin_value_and_bins_weighted_value:\n",
    "            sse_value_mg_for_kmeans  +=  (i  -  avg) * (i  -  avg)\n",
    "    return sse_value_mg_for_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterNum = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_kmeans_model_to_output_the_required_values  =  KMeans(n_clusters = clusterNum ,  random_state = 0).fit(list_containing_the_final_feature_matrix_for_the_meal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_copy_of_the_meal_amount_in_bins_of_size_20  =  meal_amount_in_bins_of_size_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_bins_by_the_kmeans_model  =  get_BinsMG(generating_kmeans_model_to_output_the_required_values.labels_ ,  list_copy_of_the_meal_amount_in_bins_of_size_20 ,  clusterNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_bins_by_the_kmeans_model\n",
      "[[3, 3, 1, 2, 6, 5, 3, 5, 2, 1, 2, 3, 3, 4, 2, 2, 2, 5, 2, 1, 2, 5, 3, 4, 6, 2, 4, 2, 2, 1, 2, 2, 1, 3, 5, 3, 3, 3, 2, 5, 2, 1, 2, 4, 3, 1, 3, 4, 2, 2, 5, 1, 3, 3, 4, 2, 1, 3, 1, 3, 1, 3, 1, 1, 1, 2, 1, 2, 2, 4, 1, 2, 4, 3, 4, 3, 2, 1, 2, 2, 3, 3, 1, 4, 2, 2, 3, 2, 2, 1, 2, 4, 2, 1, 2, 5, 4, 1, 2, 3, 2, 1, 3, 1, 1, 3, 1, 2, 3, 1, 1, 1, 3, 1, 3, 2, 1, 2, 2], [3, 6, 2, 5, 2, 2, 2, 4, 3, 1, 1, 3, 3, 2, 2, 4, 3, 3, 3, 2, 3, 3, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 3, 2, 1, 3, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 5, 3, 3, 4, 2, 4], [2, 5, 3, 3, 2, 1, 2, 3], [4, 4, 2, 3, 5, 1, 1, 2, 2, 5, 3, 1, 3, 3, 3, 2, 5, 1, 3, 1, 2, 4, 4, 3, 1, 1, 3, 3, 5, 3, 1, 2, 4, 1, 1, 4, 5, 3, 2, 2, 2, 5, 2, 4, 2, 2, 3, 2, 2, 2], [4, 1, 6, 2, 5, 4, 1, 2, 2, 5, 3, 2, 4, 1, 2], [3, 1, 3, 3, 1, 3, 2, 2, 3, 3, 3, 3, 4, 5, 3, 5, 1, 3, 2, 2, 4, 2, 3, 2, 2, 1, 3, 1, 4, 4, 4, 2, 1, 5, 1, 1, 1, 2, 3, 2, 3, 3, 1, 2, 5, 1, 4, 2, 1, 5, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"generated_bins_by_the_kmeans_model\")\n",
    "print(generated_bins_by_the_kmeans_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeansSSE  =  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_bins_by_the_kmeans_model)):\n",
    "    kMeansSSE  +=  (compute_SSEValueMG_for_kmeans_calculation(generated_bins_by_the_kmeans_model[i]) * len(generated_bins_by_the_kmeans_model[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating_a_kmeans_contingency_matrix_to_calculate_the_values_required_for_the_output  =  contingency_matrix(list_copy_of_the_meal_amount_in_bins_of_size_20 ,  generating_kmeans_model_to_output_the_required_values.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculating_entropy_from_the_generated_kmeans_model_and_kmeans_contingency_matrix ,  calculating_purity_MG_from_the_generated_kmeans_model_and_kmeans_contingency_matrix  =  [] ,  []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for single_kmeans_model_cluster in generating_a_kmeans_contingency_matrix_to_calculate_the_values_required_for_the_output:\n",
    "    single_kmeans_model_cluster  =  single_kmeans_model_cluster / float(single_kmeans_model_cluster.sum())\n",
    "    calculting_the_temporary_entropy_mg_value_to_calculate_the_final_entropy_value  =  0\n",
    "    for x in single_kmeans_model_cluster :\n",
    "        if x !=  0 :\n",
    "            calculting_the_temporary_entropy_mg_value_to_calculate_the_final_entropy_value  =  (single_kmeans_model_cluster * [math.log(x ,  2)]).sum()* - 1\n",
    "        else:\n",
    "            calculting_the_temporary_entropy_mg_value_to_calculate_the_final_entropy_value  =  single_kmeans_model_cluster.sum()\n",
    "    single_kmeans_model_cluster  =  single_kmeans_model_cluster*3.5\n",
    "    calculating_entropy_from_the_generated_kmeans_model_and_kmeans_contingency_matrix  +=  [calculting_the_temporary_entropy_mg_value_to_calculate_the_final_entropy_value]\n",
    "    calculating_purity_MG_from_the_generated_kmeans_model_and_kmeans_contingency_matrix  +=  [single_kmeans_model_cluster.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts  =  np.array([c.sum() for c in generating_a_kmeans_contingency_matrix_to_calculate_the_values_required_for_the_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs  =  counts / float(counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_final_kmeans_entropy_value  =  (coeffs * calculating_entropy_from_the_generated_kmeans_model_and_kmeans_contingency_matrix).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_final_kMeanspurity_MG_value  =  (coeffs * calculating_purity_MG_from_the_generated_kmeans_model_and_kmeans_contingency_matrix).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
